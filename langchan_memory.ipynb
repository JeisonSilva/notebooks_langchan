{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da288765",
   "metadata": {},
   "source": [
    "### 1. Configuração do Ambiente (Setup)\n",
    "\n",
    "O primeiro passo é configurar nosso ambiente de desenvolvimento. Isso envolve a instalação de todas as bibliotecas (pacotes NuGet) necessárias para o projeto.\n",
    "\n",
    "- **LangChain & LangChain.Providers.OpenAI**: O núcleo do framework LangChain e o provedor específico para interagir com os modelos da OpenAI.\n",
    "- **Microsoft.Extensions.Caching.Memory**: Utilizado para implementações de cache em memória, que pode ser usado pelo LangChain para otimizar chamadas repetidas.\n",
    "- **DotNetEnv**: Uma biblioteca auxiliar para carregar variáveis de ambiente de um arquivo `.env`, facilitando o gerenciamento de chaves de API e outras configurações sensíveis de forma segura."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7180a045",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div></div><div></div><div><strong>Installed Packages</strong><ul><li><span>DotNetEnv, 3.1.1</span></li><li><span>LangChain, 0.17.0</span></li><li><span>LangChain.Providers.OpenAI, 0.17.0</span></li><li><span>microsoft.extensions.caching.abstractions, 10.0.2</span></li><li><span>Microsoft.Extensions.Caching.Memory, 10.0.2</span></li></ul></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#r \"nuget: LangChain\"\n",
    "#r \"nuget: LangChain.Providers.OpenAI\"\n",
    "#r \"nuget: Microsoft.Extensions.Caching.Memory\"\n",
    "#r \"nuget: Microsoft.Extensions.Caching.Abstractions\"\n",
    "#r \"nuget: DotNetEnv, 3.1.1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "new-md-1",
   "metadata": {},
   "source": [
    "A seguir, carregamos a chave de API da OpenAI a partir de um arquivo `.env`. Armazenar a chave em um arquivo de variáveis de ambiente é uma boa prática de segurança para evitar que informações sensíveis sejam expostas diretamente no código."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7baf36c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "using DotNetEnv;\n",
    "\n",
    "var PathDocuments = System.Environment.GetFolderPath(System.Environment.SpecialFolder.MyDocuments);\n",
    "var FilePath = System.IO.Path.Combine(PathDocuments, \"estudos/langchan/.env\");\n",
    "\n",
    "Env.Load(FilePath);\n",
    "string apiKey = Environment.GetEnvironmentVariable(\"API_KEY\") ?? throw new InvalidOperationException(\"API_KEY not found in environment variables.\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19d6efc",
   "metadata": {},
   "source": [
    "### 2. Definição do Modelo e do Template de Prompt\n",
    "\n",
    "Com o ambiente configurado, definimos os dois componentes principais para a nossa conversa:\n",
    "\n",
    "1.  **Modelo (`model`)**: Instanciamos o `OpenAiLatestFastChatModel`, que representa o modelo de linguagem da OpenAI que irá gerar as respostas. Ele é inicializado com a chave de API que carregamos anteriormente.\n",
    "2.  **Template de Prompt (`template`)**: O template é uma estrutura de texto que define como a entrada do usuário e o histórico da conversa serão formatados antes de serem enviados ao modelo.\n",
    "    - `{history}`: É um placeholder onde o LangChain irá inserir o histórico da conversa.\n",
    "    - `{input}`: É um placeholder para a nova entrada do usuário.\n",
    "\n",
    "Essa estrutura ajuda o modelo a entender o contexto da conversa e a gerar respostas mais coerentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "55d07468",
   "metadata": {},
   "outputs": [],
   "source": [
    "using LangChain.Providers.OpenAI.Predefined;\n",
    "\n",
    "var model = new OpenAiLatestFastChatModel(apiKey);\n",
    "var template = @\"Você é um programador experiente em C# que está apoiando um desenvolvedor Senior nos testes.\n",
    "{history}\n",
    "Usuário: {input}\n",
    "Programador experiente:\";"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217a1298",
   "metadata": {},
   "source": [
    "### 3. Implementação da Memória Conversacional\n",
    "\n",
    "Para que o chatbot \"lembre\" das interações passadas, implementamos uma estratégia de memória. O LangChain oferece várias estratégias, e aqui estamos construindo uma `ConversationBufferMemory`.\n",
    "\n",
    "- **`GetBaseChatMessageHistory()`**: Cria uma instância de `ChatMessageHistory`, que é um armazenamento em memória simples para as mensagens da conversa.\n",
    "- **`GetConversationBufferMemory(...)`**: Cria a `ConversationBufferMemory`, que utiliza o `ChatMessageHistory` para guardar as mensagens. Também configuramos um `MessageFormatter` para definir prefixos customizados para as mensagens do usuário (\"Usuário:\") e da IA (\"Programador experiente:\").\n",
    "- **`PickMemoryStrategy(...)`**: Junta todas as peças, criando e retornando a estratégia de memória configurada que será usada pela nossa cadeia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6b5604a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "private static BaseChatMemory GetConversationBufferMemory(BaseChatMessageHistory chatHistory, MessageFormatter messageFormatter)\n",
    "    {\n",
    "        return new ConversationBufferMemory(chatHistory)\n",
    "        {\n",
    "            Formatter = messageFormatter\n",
    "        };\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3bc85b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "using LangChain.Memory;\n",
    "\n",
    "private static BaseChatMessageHistory GetBaseChatMessageHistory()\n",
    "{\n",
    "    return new ChatMessageHistory();\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5553df97",
   "metadata": {},
   "outputs": [],
   "source": [
    "using LangChain.Memory;\n",
    "using LangChain.Providers;\n",
    "\n",
    "private static BaseChatMemory PickMemoryStrategy(IChatModel model)\n",
    "{\n",
    "    MessageFormatter formatter = new MessageFormatter\n",
    "    {\n",
    "        AiPrefix = \"Programador experiente\",\n",
    "        HumanPrefix = \"Usuário\"\n",
    "    };\n",
    "\n",
    "    BaseChatMessageHistory chatHistory = GetBaseChatMessageHistory();\n",
    "\n",
    "    return GetConversationBufferMemory(chatHistory, formatter);\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "new-md-2",
   "metadata": {},
   "source": [
    "### 4. Composição da Cadeia (Chain)\n",
    "\n",
    "Agora, montamos a \"cadeia\" (chain), que é a sequência de passos que serão executados em ordem. Utilizamos o operador `|` para conectar cada componente:\n",
    "\n",
    "1.  **`LoadMemory(...)`**: O primeiro passo carrega o histórico da conversa da memória (usando a estratégia que definimos) e o insere na variável `history`, que será usada pelo template.\n",
    "2.  **`Template(...)`**: Formata o prompt com o histórico e a nova entrada do usuário.\n",
    "3.  **`LLM(...)`**: Envia o prompt formatado para o modelo da OpenAI. A resposta do modelo será, por padrão, colocada na variável `text`.\n",
    "4.  **`UpdateMemory(...)`**: O último passo atualiza a memória da conversa, salvando a pergunta do usuário (da variável `input`) e a resposta da IA (da variável `text`) para serem usadas nas próximas interações."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4eba3556",
   "metadata": {},
   "outputs": [],
   "source": [
    "using static LangChain.Chains.Chain;\n",
    "\n",
    "var chain = \n",
    "    LoadMemory(PickMemoryStrategy(model), \"history\")\n",
    "    | Template(template)\n",
    "    | LLM(model)\n",
    "    | UpdateMemory(PickMemoryStrategy(model), requestKey: \"input\", responseKey: \"text\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54f2498",
   "metadata": {},
   "source": [
    "### 5. Execução da Cadeia\n",
    "\n",
    "Finalmente, executamos a cadeia.\n",
    "\n",
    "1.  **`Set(\"Ola como vc está:\", \"input\")`**: Primeiro, usamos a cadeia `Set` para definir a pergunta inicial do usuário. O texto \"Ola como vc está:\" é colocado na variável `input`.\n",
    "2.  **`| chain`**: Conectamos esta entrada à cadeia principal que construímos no passo anterior.\n",
    "3.  **`finalChain.RunAsync(\"text\")`**: Executamos a cadeia completa de forma assíncrona e pedimos o valor da variável de saída `text`, que conterá a resposta gerada pelo modelo.\n",
    "4.  **`Console.WriteLine(result)`**: Imprimimos o resultado no console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1389b9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "var finalChain = Set(\"Ola como vc está:\", \"input\") | chain;\n",
    "var result = await finalChain.RunAsync(\"text\");\n",
    "\n",
    "Console.WriteLine(result);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".NET (C#)",
   "language": "C#",
   "name": ".net-csharp"
  },
  "language_info": {
   "name": "polyglot-notebook"
  },
  "polyglot_notebook": {
   "kernelInfo": {
    "defaultKernelName": "csharp",
    "items": [
     {
      "aliases": [],
      "languageName": "csharp",
      "name": "csharp"
     }
    ]
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}